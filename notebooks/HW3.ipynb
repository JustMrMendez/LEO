{"cells": [{"cell_type": "markdown", "id": "2638b51f", "metadata": {}, "source": ["# CAP5610 HW3 \u2013 Tree Ensembles & SHAP\n", "\n", "This notebook documents the end-to-end pipeline required for Homework 3.\n", "Each section mirrors the assignment tasks and records both rationale and results so the workflow reads like a mini research report."]}, {"cell_type": "markdown", "id": "4ea06a8a", "metadata": {}, "source": ["## Experimental Frame\n", "- **Data**: `lncRNA_5_Cancers.csv` (classification) and `GDSC2_13drugs.csv` (regression).\n", "- **Models**: Decision Tree, Random Forest, Gradient Boosting, XGBoost, LightGBM, CatBoost.\n", "- **Metrics**: Accuracy/F1 for Task 1; MAE/MSE/RMSE/R\u00b2 for Task 3.\n", "- **Interpretability**: SHAP TreeExplainer on the winning models (Tasks 2 & 4).\n", "- **Reproducibility**: shared config (random seed, feature caps, SHAP sample limits) defined once below."]}, {"cell_type": "code", "execution_count": null, "id": "04c9b106", "metadata": {}, "outputs": [], "source": ["# Environment priming \u2013 import helper module and align configuration.\n", "from importlib import reload\n", "from pathlib import Path\n", "\n", "import numpy as np\n", "import pandas as pd\n", "from IPython.display import display\n", "\n", "import src.leo.HW3_Mendez as hw3\n", "reload(hw3)  # guarantee we are using the latest script revision when iterating in the notebook\n", "\n", "# Tweakable laboratory knobs (kept modest so laptops do not choke)\n", "hw3.MAX_FEATURES_CLASSIF = 1000\n", "hw3.MAX_FEATURES_REGRESS = 1200\n", "hw3.SHAP_SAMPLES_PER_CLASS = 30\n", "hw3.SHAP_SAMPLES_REG = 100\n", "\n", "ROOT = Path.cwd()\n", "CANCER_PATH = hw3.resolve_data_path(hw3.CANCER_CSV, hw3.CANCER_FALLBACK)\n", "REG_PATH = hw3.resolve_data_path(hw3.GDSC2_CSV, hw3.GDSC2_FALLBACK)\n", "\n", "assert CANCER_PATH is not None, \"Classification CSV missing \u2013 checked primary and fallback paths.\"\n", "assert REG_PATH is not None, \"Regression CSV missing \u2013 checked primary and fallback paths.\"\n", "\n", "hw3.log(f\"Notebook ready. Using {Path(CANCER_PATH).name} and {Path(REG_PATH).name}.\")"]}, {"cell_type": "markdown", "id": "5a10a0a0", "metadata": {}, "source": ["## Task 1 \u2014 Classification Dataset Recon\n", "We begin by loading the lncRNA expression matrix, enforcing the same feature cap used in the script.\n", "Capturing shapes and identifier columns up front makes it easy to track provenance in the write-up."]}, {"cell_type": "code", "execution_count": null, "id": "765e7b3a", "metadata": {}, "outputs": [], "source": ["Xc, yc, ids, target_col, id_col = hw3.memory_savvy_read_cancers(str(CANCER_PATH), hw3.MAX_FEATURES_CLASSIF)\n", "\n", "summary_cls = pd.DataFrame(\n", "    {\n", "        \"rows\": [len(Xc)],\n", "        \"features\": [Xc.shape[1]],\n", "        \"target\": [target_col],\n", "        \"id_column\": [id_col],\n", "    }\n", ")\n", "\n", "display(summary_cls)\n", "# Peek at a slice of the feature matrix (5 samples \u00d7 10 genes) for sanity.\n", "Xc.iloc[:5, :10]\n"]}, {"cell_type": "markdown", "id": "ff559762", "metadata": {}, "source": ["## Task 1 \u2014 Model Selection\n", "We run the tree-ensemble suite with shared preprocessing (median imputation).\n", "The helper returns both the comparison table and the fitted pipelines so we can reuse the best model downstream."]}, {"cell_type": "code", "execution_count": null, "id": "a50b27d9", "metadata": {}, "outputs": [], "source": ["cls_results, cls_models, idx_to_class = hw3.train_compare_classifiers(Xc, yc, hw3.RANDOM_STATE)\n", "\n", "display(cls_results)\n", "\n", "best_cls_name = cls_results.iloc[0][\"Model\"]\n", "best_classifier = cls_models[best_cls_name]\n", "\n", "hw3.log(f\"Task 1 best classifier: {best_cls_name}\")\n"]}, {"cell_type": "markdown", "id": "924faea9", "metadata": {}, "source": ["## Task 2 \u2014 SHAP Analysis on Winning Classifier\n", "Using the same sampled dataset as the script, we compute per-cancer SHAP importance tables and force plots for the specified patient.\n", "Outputs land in `hw3_outputs/` so they can be embedded into the report."]}, {"cell_type": "code", "execution_count": null, "id": "41165a70", "metadata": {}, "outputs": [], "source": ["hw3.shap_task2(best_classifier, Xc, yc, ids, hw3.PATIENT_ID_TO_PLOT, idx_to_class)\n", "\n", "# Display the aggregated top-10 table to keep the narrative close to the numbers.\n", "task2_table = pd.read_csv(hw3.OUT_DIR / \"task2a_top10_features_per_cancer.csv\")\n", "\n", "task2_table.head(15)\n"]}, {"cell_type": "markdown", "id": "543f1fdb", "metadata": {}, "source": ["## Task 3 \u2014 Regression Dataset Recon\n", "Next, load the drug screening panel, summarise the dimensionality, and retain the composite key (`CELL_LINE_NAME|DRUG_NAME`)."]}, {"cell_type": "code", "execution_count": null, "id": "c6896b17", "metadata": {}, "outputs": [], "source": ["Xr, yr, keys, meta = hw3.memory_savvy_read_gdsc2(str(REG_PATH), hw3.MAX_FEATURES_REGRESS)\n", "\n", "summary_reg = pd.DataFrame(\n", "    {\n", "        \"rows\": [meta[\"n_rows\"]],\n", "        \"features\": [meta[\"n_features\"]],\n", "        \"target\": [meta[\"target\"]],\n", "        \"id_columns\": [\" & \".join(meta[\"id_cols\"])]\n", "    }\n", ")\n", "\n", "display(summary_reg)\n", "Xr.iloc[:5, :10]\n"]}, {"cell_type": "markdown", "id": "4a8327b4", "metadata": {}, "source": ["## Task 3 \u2014 Model Selection\n", "Repeat the ensemble sweep for regression, collecting all four metrics. The winning pipeline feeds Task 4."]}, {"cell_type": "code", "execution_count": null, "id": "75810cf5", "metadata": {}, "outputs": [], "source": ["reg_results, reg_models = hw3.train_compare_regressors(Xr, yr, hw3.RANDOM_STATE)\n", "\n", "display(reg_results)\n", "\n", "best_reg_name = reg_results.iloc[0][\"Model\"]\n", "best_regressor = reg_models[best_reg_name]\n", "\n", "hw3.log(f\"Task 3 best regressor: {best_reg_name}\")\n"]}, {"cell_type": "markdown", "id": "eef1f13a", "metadata": {}, "source": ["## Task 4 \u2014 SHAP on Winning Regressor\n", "Finally we generate per-drug importances and inspect the least-error drug\u2013cell line pair using SHAP contributions."]}, {"cell_type": "code", "execution_count": null, "id": "d661b092", "metadata": {}, "outputs": [], "source": ["hw3.shap_task4(best_regressor, Xr, yr, keys)\n", "\n", "task4a_table = pd.read_csv(hw3.OUT_DIR / \"task4a_top10_features_per_drug.csv\")\n", "task4b_path = sorted(hw3.OUT_DIR.glob(\"task4b_top10_features_least_error_*.csv\"))[-1]\n", "task4b_table = pd.read_csv(task4b_path)\n", "\n", "(task4a_table.head(20), task4b_table)\n"]}, {"cell_type": "markdown", "id": "14dbf2b2", "metadata": {}, "source": ["## Conclusion & Artifacts\n", "- Metrics and SHAP exports live under `hw3_outputs/` for inclusion in the written report.\n", "- Adjust `MAX_FEATURES_*` or SHAP sample counts above if you need faster prototypes or deeper feature sweeps.\n", "- Re-run individual cells to regenerate specific figures without repeating the full pipeline."]}], "metadata": {}, "nbformat": 4, "nbformat_minor": 5}