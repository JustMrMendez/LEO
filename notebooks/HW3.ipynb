{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3f791805",
   "metadata": {},
   "source": [
    "# CAP5610 HW3 — Tree Ensembles & SHAP Study\n",
    "\n",
    "This notebook mirrors Homework 3 and is self-contained: with the two datasets (`lncRNA_5_Cancers.csv` and `hw3-drug-screening-data.csv`) placed beside it, you can rerun every block to regenerate the figures, tables, and SHAP artefacts required in the assignment."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79d8bed0",
   "metadata": {},
   "source": [
    "## Study Roadmap\n",
    "1. **Shared setup** — import libraries, configure reproducible knobs, and define reusable helpers.\n",
    "2. **Task 1** — explore the classification dataset and benchmark tree-based classifiers.\n",
    "3. **Task 2** — interpret the best classifier with SHAP (per-cancer importances + patient force plots).\n",
    "4. **Task 3** — profile the regression dataset and compare regressors on MAE/MSE/RMSE/R².\n",
    "5. **Task 4** — run SHAP on the winning regressor for drug-specific insights and least-error explanation.\n",
    "6. **Conclusion** — summarise artefacts and next steps."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "544f89dc",
   "metadata": {},
   "source": [
    "## 0. Shared Setup & Reusable Utilities\n",
    "The following cell loads all required libraries, defines runtime configuration (random seed, feature caps, SHAP sampling budgets), and introduces helper routines for logging and path resolution. Keeping the helpers here ensures the notebook is standalone."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "04802d51",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'numpy'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 11\u001b[39m\n\u001b[32m      8\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mwarnings\u001b[39;00m\n\u001b[32m      9\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtyping\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Dict, List, Optional, Tuple\n\u001b[32m---> \u001b[39m\u001b[32m11\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnp\u001b[39;00m\n\u001b[32m     12\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpd\u001b[39;00m\n\u001b[32m     13\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mIPython\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdisplay\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m display, HTML\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'numpy'"
     ]
    }
   ],
   "source": [
    "# --- Imports & global configuration -------------------------------------------------\n",
    "from pathlib import Path\n",
    "import gc\n",
    "import json\n",
    "import math\n",
    "import re\n",
    "import time\n",
    "import warnings\n",
    "from typing import Dict, List, Optional, Tuple\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.ensemble import (\n",
    "    GradientBoostingClassifier,\n",
    "    GradientBoostingRegressor,\n",
    "    RandomForestClassifier,\n",
    "    RandomForestRegressor,\n",
    ")\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    classification_report,\n",
    "    confusion_matrix,\n",
    "    f1_score,\n",
    "    mean_absolute_error,\n",
    "    mean_squared_error,\n",
    "    r2_score,\n",
    ")\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor\n",
    "\n",
    "try:\n",
    "    from xgboost import XGBClassifier, XGBRegressor\n",
    "    HAVE_XGB = True\n",
    "except Exception:\n",
    "    HAVE_XGB = False\n",
    "\n",
    "try:\n",
    "    from lightgbm import LGBMClassifier, LGBMRegressor\n",
    "    HAVE_LGBM = True\n",
    "except Exception:\n",
    "    HAVE_LGBM = False\n",
    "\n",
    "try:\n",
    "    from catboost import CatBoostClassifier, CatBoostRegressor\n",
    "    HAVE_CAT = True\n",
    "except Exception:\n",
    "    HAVE_CAT = False\n",
    "\n",
    "try:\n",
    "    import shap\n",
    "    HAVE_SHAP = True\n",
    "except Exception:\n",
    "    HAVE_SHAP = False\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "\n",
    "RANDOM_STATE = 42\n",
    "CANCER_SET = {\"KIRC\", \"LUAD\", \"LUSC\", \"PRAD\", \"THCA\"}\n",
    "PATIENT_ID_TO_PLOT = \"TCGA-39-5011-01A\"\n",
    "\n",
    "CANCER_PRIMARY = Path(\"lncRNA_5_Cancers.csv\")\n",
    "CANCER_FALLBACK = Path(\"data/raw/lncRNA_5_Cancers.csv\")\n",
    "REG_PRIMARY = Path(\"GDSC2_13drugs.csv\")\n",
    "REG_FALLBACK = Path(\"data/raw/hw3-drug-screening-data.csv\")\n",
    "\n",
    "OUT_DIR = Path(\"hw3_outputs\")\n",
    "OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "MAX_FEATURES_CLASSIF = 1000\n",
    "MAX_FEATURES_REGRESS = 1200\n",
    "SHAP_SAMPLES_PER_CLASS = 30\n",
    "SHAP_SAMPLES_REG = 100\n",
    "BACKGROUND_SIZE = 200\n",
    "\n",
    "\n",
    "def log(message: str) -> None:\n",
    "    stamp = time.strftime(\"%H:%M:%S\")\n",
    "    print(f\"[{stamp}] {message}\")\n",
    "\n",
    "\n",
    "def resolve_data_path(primary: Path, fallback: Optional[Path]) -> Optional[Path]:\n",
    "    for candidate in (primary, fallback):\n",
    "        if candidate is None:\n",
    "            continue\n",
    "        candidate_path = Path(candidate)\n",
    "        if candidate_path.exists():\n",
    "            return candidate_path\n",
    "    return None\n",
    "\n",
    "\n",
    "def select_top_variance_features(frame: pd.DataFrame, max_features: int) -> pd.DataFrame:\n",
    "    if frame.shape[1] <= max_features:\n",
    "        return frame\n",
    "    variances = frame.var(axis=0, skipna=True)\n",
    "    top_cols = variances.nlargest(max_features).index\n",
    "    return frame.loc[:, top_cols]\n",
    "\n",
    "\n",
    "def tree_background(sample: np.ndarray) -> np.ndarray:\n",
    "    if sample.shape[0] <= BACKGROUND_SIZE:\n",
    "        return sample\n",
    "    rng = np.random.default_rng(RANDOM_STATE)\n",
    "    idx = rng.choice(sample.shape[0], size=BACKGROUND_SIZE, replace=False)\n",
    "    return sample[idx]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a25e6002",
   "metadata": {},
   "source": [
    "## 1. Data Loading Utilities\n",
    "These loaders detect identifier/target columns, enforce numeric typing, drop all-NaN features, and apply the variance cap defined above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c41718f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_id_and_target(df: pd.DataFrame) -> Tuple[Optional[str], Optional[str]]:\n",
    "    id_col = None\n",
    "    target_col = None\n",
    "    for col in df.select_dtypes(include=[\"object\"]).columns:\n",
    "        if df[col].astype(str).str.contains(r\"^TCGA-\", na=False).any():\n",
    "            id_col = col\n",
    "            break\n",
    "    if id_col is None:\n",
    "        for col in df.columns:\n",
    "            if re.search(r\"(id|patient|sample)\", col, re.I) and df[col].nunique(dropna=True) > 10:\n",
    "                id_col = col\n",
    "                break\n",
    "    for col in df.columns:\n",
    "        values = set(map(str, df[col].dropna().unique()))\n",
    "        if values.issubset(CANCER_SET) and len(values) == len(CANCER_SET):\n",
    "            target_col = col\n",
    "            break\n",
    "    if target_col is None:\n",
    "        for col in df.columns:\n",
    "            if re.search(r\"(cancer|type|label|class)\", col, re.I):\n",
    "                target_col = col\n",
    "                break\n",
    "    return id_col, target_col\n",
    "\n",
    "\n",
    "def memory_savvy_read_cancers(csv_path: Path, max_features: int) -> Tuple[pd.DataFrame, pd.Series, Optional[pd.Series], str, Optional[str]]:\n",
    "    header_cols = pd.read_csv(csv_path, nrows=0).columns.tolist()\n",
    "    sample_df = pd.read_csv(csv_path, nrows=200)\n",
    "    id_col, target_col = detect_id_and_target(sample_df)\n",
    "    if target_col is None:\n",
    "        raise RuntimeError(\"Unable to detect target column in classification dataset.\")\n",
    "\n",
    "    feature_cols = [c for c in header_cols if c not in {id_col, target_col}]\n",
    "    selected_cols = feature_cols[:max_features]\n",
    "    usecols = [target_col] + ([id_col] if id_col else []) + selected_cols\n",
    "\n",
    "    df = pd.read_csv(csv_path, usecols=usecols)\n",
    "    y = df[target_col].astype(str)\n",
    "    X = df.drop(columns=[target_col])\n",
    "\n",
    "    ids = None\n",
    "    if id_col and id_col in X.columns:\n",
    "        ids = X[id_col].astype(str)\n",
    "        X = X.drop(columns=[id_col])\n",
    "\n",
    "    for col in X.columns:\n",
    "        X[col] = pd.to_numeric(X[col], errors=\"coerce\")\n",
    "    X = X.astype(np.float32)\n",
    "    X = X.loc[:, X.notna().any(axis=0)]\n",
    "    X = select_top_variance_features(X, max_features)\n",
    "    return X, y, ids, target_col, id_col\n",
    "\n",
    "\n",
    "def memory_savvy_read_gdsc2(csv_path: Path, max_features: int) -> Tuple[pd.DataFrame, pd.Series, pd.Series, Dict[str, object]]:\n",
    "    header_cols = pd.read_csv(csv_path, nrows=0).columns.tolist()\n",
    "    target_col = \"LN_IC50\"\n",
    "\n",
    "    id_cols: List[str] = []\n",
    "    for cand in [\"CELL_LINE_NAME\", \"cell_line\", \"CELL_LINE\", \"CellLine\", \"cellLine\", \"cell_line_name\"]:\n",
    "        if cand in header_cols:\n",
    "            id_cols.append(cand)\n",
    "            break\n",
    "    for cand in [\"DRUG_NAME\", \"drug_name\", \"Drug\", \"DRUG\", \"drug\"]:\n",
    "        if cand in header_cols:\n",
    "            id_cols.append(cand)\n",
    "            break\n",
    "\n",
    "    if target_col not in header_cols:\n",
    "        raise RuntimeError(\"Expected LN_IC50 column missing in regression dataset.\")\n",
    "    if not id_cols:\n",
    "        raise RuntimeError(\"Could not detect cell line / drug identifier columns.\")\n",
    "\n",
    "    feature_cols = [c for c in header_cols if c not in id_cols + [target_col]]\n",
    "    selected_cols = feature_cols[:max_features]\n",
    "    usecols = id_cols + [target_col] + selected_cols\n",
    "\n",
    "    df = pd.read_csv(csv_path, usecols=usecols)\n",
    "    y = pd.to_numeric(df[target_col], errors=\"coerce\").astype(np.float32)\n",
    "\n",
    "    if len(id_cols) >= 2:\n",
    "        keys = df[id_cols[0]].astype(str) + \"|\" + df[id_cols[1]].astype(str)\n",
    "    else:\n",
    "        keys = df[id_cols[0]].astype(str)\n",
    "\n",
    "    X = df.drop(columns=id_cols + [target_col])\n",
    "    for col in X.columns:\n",
    "        X[col] = pd.to_numeric(X[col], errors=\"coerce\")\n",
    "    X = X.astype(np.float32)\n",
    "    X = X.loc[:, X.notna().any(axis=0)]\n",
    "    X = select_top_variance_features(X, max_features)\n",
    "    meta = {\n",
    "        \"n_rows\": len(df),\n",
    "        \"n_features\": X.shape[1],\n",
    "        \"id_cols\": id_cols,\n",
    "        \"target\": target_col,\n",
    "    }\n",
    "    return X, y, keys, meta\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "444c082d",
   "metadata": {},
   "source": [
    "## 2. Modelling & SHAP Utilities\n",
    "These helpers encapsulate the repetitive parts of Tasks 1–4: training the model suites, logging metrics, and generating SHAP summaries. Artefacts are written to `hw3_outputs/` for direct inclusion in the report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7603f0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_compare_classifiers(X: pd.DataFrame, y: pd.Series, random_state: int) -> Tuple[pd.DataFrame, Dict[str, Pipeline], Dict[int, str]]:\n",
    "    class_names = sorted(y.astype(str).unique())\n",
    "    class_to_idx = {c: i for i, c in enumerate(class_names)}\n",
    "    idx_to_class = {i: c for c, i in class_to_idx.items()}\n",
    "    y_encoded = y.map(class_to_idx).astype(int)\n",
    "\n",
    "    X_train, X_test, y_train_enc, y_test_enc, y_train_lbl, y_test_lbl = train_test_split(\n",
    "        X,\n",
    "        y_encoded,\n",
    "        y,\n",
    "        test_size=0.2,\n",
    "        random_state=random_state,\n",
    "        stratify=y,\n",
    "    )\n",
    "\n",
    "    preprocess = ColumnTransformer([(\"num\", SimpleImputer(strategy=\"median\"), X.columns)], remainder=\"drop\")\n",
    "\n",
    "    models: Dict[str, Pipeline] = {}\n",
    "    models[\"DecisionTree\"] = Pipeline([\n",
    "        (\"prep\", preprocess),\n",
    "        (\"clf\", DecisionTreeClassifier(random_state=random_state, min_samples_leaf=2, class_weight=\"balanced\")),\n",
    "    ])\n",
    "    models[\"RandomForest\"] = Pipeline([\n",
    "        (\"prep\", preprocess),\n",
    "        (\"clf\", RandomForestClassifier(n_estimators=120, random_state=random_state, n_jobs=-1, class_weight=\"balanced_subsample\")),\n",
    "    ])\n",
    "    models[\"GBM\"] = Pipeline([\n",
    "        (\"prep\", preprocess),\n",
    "        (\"clf\", GradientBoostingClassifier(n_estimators=120, learning_rate=0.05, max_depth=3, random_state=random_state)),\n",
    "    ])\n",
    "\n",
    "    if HAVE_XGB:\n",
    "        models[\"XGBoost\"] = Pipeline([\n",
    "            (\"prep\", preprocess),\n",
    "            (\"clf\", XGBClassifier(\n",
    "                objective=\"multi:softprob\",\n",
    "                eval_metric=\"mlogloss\",\n",
    "                n_estimators=160,\n",
    "                learning_rate=0.05,\n",
    "                max_depth=6,\n",
    "                subsample=0.8,\n",
    "                colsample_bytree=0.8,\n",
    "                tree_method=\"hist\",\n",
    "                n_jobs=-1,\n",
    "                random_state=random_state,\n",
    "            )),\n",
    "        ])\n",
    "    if HAVE_LGBM:\n",
    "        models[\"LightGBM\"] = Pipeline([\n",
    "            (\"prep\", preprocess),\n",
    "            (\"clf\", LGBMClassifier(\n",
    "                n_estimators=160,\n",
    "                learning_rate=0.05,\n",
    "                num_leaves=63,\n",
    "                subsample=0.8,\n",
    "                colsample_bytree=0.8,\n",
    "                random_state=random_state,\n",
    "                verbosity=-1,\n",
    "            )),\n",
    "        ])\n",
    "    if HAVE_CAT:\n",
    "        models[\"CatBoost\"] = Pipeline([\n",
    "            (\"prep\", preprocess),\n",
    "            (\"clf\", CatBoostClassifier(iterations=160, learning_rate=0.05, depth=6, loss_function=\"MultiClass\", random_seed=random_state, verbose=False)),\n",
    "        ])\n",
    "\n",
    "    rows = []\n",
    "    fitted = {}\n",
    "    for name, pipe in models.items():\n",
    "        log(f\"[Task 1] Training classifier: {name}\")\n",
    "        pipe.fit(X_train, y_train_enc)\n",
    "        y_pred_enc = pipe.predict(X_test)\n",
    "        y_pred = [idx_to_class[int(i)] for i in np.asarray(y_pred_enc, dtype=int)]\n",
    "        acc = accuracy_score(y_test_lbl, y_pred)\n",
    "        f1m = f1_score(y_test_lbl, y_pred, average=\"macro\")\n",
    "        rows.append({\"Model\": name, \"Test_Accuracy\": acc, \"Test_F1_Macro\": f1m})\n",
    "        fitted[name] = pipe\n",
    "        gc.collect()\n",
    "\n",
    "    metrics = pd.DataFrame(rows).sort_values(by=[\"Test_F1_Macro\", \"Test_Accuracy\"], ascending=False).reset_index(drop=True)\n",
    "\n",
    "    best_name = metrics.iloc[0][\"Model\"]\n",
    "    best_model = fitted[best_name]\n",
    "    y_pred_best = [idx_to_class[int(i)] for i in np.asarray(best_model.predict(X_test), dtype=int)]\n",
    "    cm = confusion_matrix(y_test_lbl, y_pred_best, labels=class_names)\n",
    "    cm_df = pd.DataFrame(cm, index=[f\"True_{c}\" for c in class_names], columns=[f\"Pred_{c}\" for c in class_names])\n",
    "    cm_df.to_csv(OUT_DIR / \"task1_confusion_matrix.csv\")\n",
    "\n",
    "    report_df = pd.DataFrame(classification_report(\n",
    "        y_test_lbl,\n",
    "        y_pred_best,\n",
    "        output_dict=True,\n",
    "        zero_division=0,\n",
    "        labels=class_names,\n",
    "        target_names=class_names,\n",
    "    )).T\n",
    "    report_df.to_csv(OUT_DIR / \"task1_classification_report.csv\")\n",
    "\n",
    "    metrics.to_csv(OUT_DIR / \"task1_model_comparison.csv\", index=False)\n",
    "    (OUT_DIR / \"task1_best_model.txt\").write_text(str(best_name))\n",
    "    return metrics, fitted, idx_to_class\n",
    "\n",
    "\n",
    "def train_compare_regressors(X: pd.DataFrame, y: pd.Series, random_state: int) -> Tuple[pd.DataFrame, Dict[str, Pipeline]]:\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=random_state)\n",
    "    preprocess = ColumnTransformer([(\"num\", SimpleImputer(strategy=\"median\"), X.columns)], remainder=\"drop\")\n",
    "\n",
    "    models: Dict[str, Pipeline] = {}\n",
    "    models[\"DecisionTreeReg\"] = Pipeline([\n",
    "        (\"prep\", preprocess),\n",
    "        (\"reg\", DecisionTreeRegressor(random_state=random_state, min_samples_leaf=2)),\n",
    "    ])\n",
    "    models[\"RandomForestReg\"] = Pipeline([\n",
    "        (\"prep\", preprocess),\n",
    "        (\"reg\", RandomForestRegressor(n_estimators=120, random_state=random_state, n_jobs=-1)),\n",
    "    ])\n",
    "    models[\"GBMReg\"] = Pipeline([\n",
    "        (\"prep\", preprocess),\n",
    "        (\"reg\", GradientBoostingRegressor(n_estimators=120, learning_rate=0.05, max_depth=3, random_state=random_state)),\n",
    "    ])\n",
    "\n",
    "    if HAVE_XGB:\n",
    "        models[\"XGBReg\"] = Pipeline([\n",
    "            (\"prep\", preprocess),\n",
    "            (\"reg\", XGBRegressor(\n",
    "                n_estimators=160,\n",
    "                learning_rate=0.05,\n",
    "                max_depth=6,\n",
    "                subsample=0.8,\n",
    "                colsample_bytree=0.8,\n",
    "                tree_method=\"hist\",\n",
    "                n_jobs=-1,\n",
    "                random_state=random_state,\n",
    "            )),\n",
    "        ])\n",
    "    if HAVE_LGBM:\n",
    "        models[\"LGBMReg\"] = Pipeline([\n",
    "            (\"prep\", preprocess),\n",
    "            (\"reg\", LGBMRegressor(\n",
    "                n_estimators=160,\n",
    "                learning_rate=0.05,\n",
    "                num_leaves=63,\n",
    "                subsample=0.8,\n",
    "                colsample_bytree=0.8,\n",
    "                random_state=random_state,\n",
    "                verbosity=-1,\n",
    "            )),\n",
    "        ])\n",
    "    if HAVE_CAT:\n",
    "        models[\"CatBoostReg\"] = Pipeline([\n",
    "            (\"prep\", preprocess),\n",
    "            (\"reg\", CatBoostRegressor(iterations=160, learning_rate=0.05, depth=6, loss_function=\"RMSE\", random_seed=random_state, verbose=False)),\n",
    "        ])\n",
    "\n",
    "    rows = []\n",
    "    fitted = {}\n",
    "    for name, pipe in models.items():\n",
    "        log(f\"[Task 3] Training regressor: {name}\")\n",
    "        pipe.fit(X_train, y_train)\n",
    "        preds = pipe.predict(X_test)\n",
    "        mae = mean_absolute_error(y_test, preds)\n",
    "        mse = mean_squared_error(y_test, preds)\n",
    "        rmse = math.sqrt(mse)\n",
    "        r2 = r2_score(y_test, preds)\n",
    "        rows.append({\"Model\": name, \"MAE\": mae, \"MSE\": mse, \"RMSE\": rmse, \"R2\": r2})\n",
    "        fitted[name] = pipe\n",
    "        gc.collect()\n",
    "\n",
    "    metrics = pd.DataFrame(rows).sort_values(by=[\"RMSE\", \"MAE\"], ascending=[True, True]).reset_index(drop=True)\n",
    "    metrics.to_csv(OUT_DIR / \"task3_regressor_comparison.csv\", index=False)\n",
    "    (OUT_DIR / \"task3_best_model.txt\").write_text(str(metrics.iloc[0][\"Model\"]))\n",
    "    return metrics, fitted\n",
    "\n",
    "\n",
    "def shap_task2(best_model: Pipeline, X: pd.DataFrame, y: pd.Series, sample_ids: Optional[pd.Series], patient_id: str, idx_to_class: Dict[int, str]) -> None:\n",
    "    if not HAVE_SHAP:\n",
    "        log(\"[Task 2] SHAP package not installed — skipping interpretability step.\")\n",
    "        return\n",
    "\n",
    "    estimator = best_model.named_steps[list(best_model.named_steps.keys())[-1]]\n",
    "    explainer = shap.TreeExplainer(estimator, feature_perturbation=\"tree_path_dependent\")\n",
    "\n",
    "    df_full = X.copy()\n",
    "    df_full[\"__y__\"] = y.values\n",
    "    idxs = []\n",
    "    rng = np.random.default_rng(RANDOM_STATE)\n",
    "    for cancer in sorted(CANCER_SET):\n",
    "        class_idx = df_full.index[df_full[\"__y__\"] == cancer].tolist()\n",
    "        if len(class_idx) > SHAP_SAMPLES_PER_CLASS:\n",
    "            class_idx = list(rng.choice(class_idx, SHAP_SAMPLES_PER_CLASS, replace=False))\n",
    "        idxs.extend(class_idx)\n",
    "    idxs = sorted(set(idxs))\n",
    "    X_shap = X.loc[idxs]\n",
    "\n",
    "    shap_raw = explainer.shap_values(X_shap)\n",
    "    if isinstance(shap_raw, list):\n",
    "        shap_by_class = shap_raw\n",
    "    else:\n",
    "        shap_arr = np.asarray(shap_raw)\n",
    "        shap_by_class = [shap_arr[:, :, i] for i in range(shap_arr.shape[2])] if shap_arr.ndim == 3 else [shap_arr]\n",
    "\n",
    "    records = []\n",
    "    classes = list(estimator.classes_) if hasattr(estimator, \"classes_\") else list(range(len(shap_by_class)))\n",
    "    for i, raw_cls in enumerate(classes):\n",
    "        display_name = idx_to_class.get(int(raw_cls), str(raw_cls))\n",
    "        mean_abs = np.abs(shap_by_class[i]).mean(axis=0)\n",
    "        top_idx = np.argsort(mean_abs)[::-1][:10]\n",
    "        for rank, feat_idx in enumerate(top_idx, start=1):\n",
    "            records.append(\n",
    "                {\n",
    "                    \"CancerType\": display_name,\n",
    "                    \"Rank\": rank,\n",
    "                    \"Feature\": X_shap.columns[feat_idx],\n",
    "                    \"Mean|SHAP|\": float(np.asarray(mean_abs[feat_idx]).reshape(-1)[0]),\n",
    "                }\n",
    "            )\n",
    "    pd.DataFrame(records).to_csv(OUT_DIR / \"task2a_top10_features_per_cancer.csv\", index=False)\n",
    "\n",
    "    shap.initjs()\n",
    "    if sample_ids is not None and sample_ids.notna().any():\n",
    "        matches = sample_ids[sample_ids.astype(str) == patient_id]\n",
    "        idx = matches.index[0] if not matches.empty else X.index[0]\n",
    "    else:\n",
    "        idx = X.index[0]\n",
    "    row = X.loc[[idx]]\n",
    "    shap_row_raw = explainer.shap_values(row)\n",
    "\n",
    "    if isinstance(shap_row_raw, list):\n",
    "        shap_rows = shap_row_raw\n",
    "    else:\n",
    "        shap_arr = np.asarray(shap_row_raw)\n",
    "        if shap_arr.ndim == 3:\n",
    "            shap_rows = [shap_arr[:, :, i] for i in range(shap_arr.shape[2])]\n",
    "        elif shap_arr.ndim == 2:\n",
    "            shap_rows = [shap_arr]\n",
    "        else:\n",
    "            shap_rows = [shap_arr.reshape(shap_arr.shape[0], -1)]\n",
    "\n",
    "    expected_values = np.asarray(explainer.expected_value)\n",
    "    inline_visuals = []\n",
    "    for i, raw_cls in enumerate(classes):\n",
    "        display_name = idx_to_class.get(int(raw_cls), str(raw_cls))\n",
    "        expected = expected_values[i] if expected_values.ndim > 0 else expected_values\n",
    "        force_plot = shap.force_plot(expected, shap_rows[i][0, :], row, feature_names=row.columns, matplotlib=False)\n",
    "        shap.save_html(str(OUT_DIR / f\"task2b_forceplot_{display_name}_patient_{patient_id.replace(':','-')}.html\"), force_plot)\n",
    "        inline_visuals.append((display_name, force_plot))\n",
    "\n",
    "    for display_name, force_plot in inline_visuals:\n",
    "        log(f\"Task 2b force plot for {display_name}\")\n",
    "        display(HTML(force_plot.html()))\n",
    "\n",
    "\n",
    "def shap_task4(best_reg_model: Pipeline, X: pd.DataFrame, y: pd.Series, keys: pd.Series) -> None:\n",
    "    if not HAVE_SHAP:\n",
    "        log(\"[Task 4] SHAP package not installed — skipping interpretability step.\")\n",
    "        return\n",
    "\n",
    "    estimator = best_reg_model.named_steps[list(best_reg_model.named_steps.keys())[-1]]\n",
    "    explainer = shap.TreeExplainer(estimator, feature_perturbation=\"tree_path_dependent\")\n",
    "\n",
    "    if keys.str.contains(r\"\\|\").any():\n",
    "        drug_names = keys.str.split(\"|\").str[1]\n",
    "    else:\n",
    "        drug_names = pd.Series([\"ALL\"] * len(keys), index=keys.index)\n",
    "\n",
    "    rng = np.random.default_rng(RANDOM_STATE)\n",
    "    sample_idx = rng.choice(X.index, size=min(SHAP_SAMPLES_REG, len(X)), replace=False)\n",
    "    X_shap = X.loc[sample_idx]\n",
    "    drugs_shap = drug_names.loc[sample_idx]\n",
    "\n",
    "    shap_vals = explainer.shap_values(X_shap)\n",
    "    shap_arr = np.asarray(shap_vals)\n",
    "    if shap_arr.ndim != 2:\n",
    "        raise ValueError(\"Unexpected SHAP output shape for regression.\")\n",
    "\n",
    "    records = []\n",
    "    for drug in sorted(drugs_shap.unique()):\n",
    "        mask = (drugs_shap == drug).values\n",
    "        if mask.sum() == 0:\n",
    "            continue\n",
    "        mean_abs = np.abs(shap_arr[mask]).mean(axis=0)\n",
    "        top_idx = np.argsort(mean_abs)[::-1][:10]\n",
    "        for rank, feat_idx in enumerate(top_idx, start=1):\n",
    "            records.append(\n",
    "                {\n",
    "                    \"Drug\": drug,\n",
    "                    \"Rank\": rank,\n",
    "                    \"Feature\": X_shap.columns[feat_idx],\n",
    "                    \"Mean|SHAP|\": float(np.asarray(mean_abs[feat_idx]).reshape(-1)[0]),\n",
    "                }\n",
    "            )\n",
    "    pd.DataFrame(records).to_csv(OUT_DIR / \"task4a_top10_features_per_drug.csv\", index=False)\n",
    "\n",
    "    preds = best_reg_model.predict(X)\n",
    "    errors = np.abs(preds - y.values)\n",
    "    idx_min = int(np.argmin(errors))\n",
    "    least_key = keys.iloc[idx_min]\n",
    "    row = X.iloc[[idx_min]]\n",
    "    shap_row = explainer.shap_values(row)[0, :]\n",
    "    mean_abs = np.abs(shap_row)\n",
    "    top_idx = np.argsort(mean_abs)[::-1][:10]\n",
    "    pd.DataFrame(\n",
    "        {\n",
    "            \"Rank\": np.arange(1, 11),\n",
    "            \"Feature\": X.columns[top_idx],\n",
    "            \"Absolute_SHAP\": mean_abs[top_idx].astype(float),\n",
    "        }\n",
    "    ).to_csv(OUT_DIR / f\"task4b_top10_features_least_error_{least_key.replace('|', '_')}.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d8ea10e",
   "metadata": {},
   "source": [
    "## 3. Task 1 — Classification Dataset Reconnaissance\n",
    "We load the lncRNA expression matrix with the memory-savvy routine. The summary table captures the sample size, retained feature count, and identifier columns for citation in the written report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60ece10c",
   "metadata": {},
   "outputs": [],
   "source": [
    "cancer_path = resolve_data_path(CANCER_PRIMARY, CANCER_FALLBACK)\n",
    "assert cancer_path is not None, \"Classification CSV missing – please place lncRNA_5_Cancers.csv alongside the notebook.\"\n",
    "\n",
    "Xc, yc, sample_ids, class_col, id_col = memory_savvy_read_cancers(cancer_path, MAX_FEATURES_CLASSIF)\n",
    "\n",
    "summary_cls = pd.DataFrame(\n",
    "    {\n",
    "        \"rows\": [len(Xc)],\n",
    "        \"selected_features\": [Xc.shape[1]],\n",
    "        \"target_column\": [class_col],\n",
    "        \"id_column\": [id_col],\n",
    "    }\n",
    ")\n",
    "\n",
    "log(\"Task 1 dataset loaded.\")\n",
    "display(summary_cls)\n",
    "Xc.iloc[:5, :10]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e83f5e4",
   "metadata": {},
   "source": [
    "## 4. Task 1 — Model Comparison\n",
    "We benchmark the required classifiers under a shared preprocessing pipeline (median imputation). Macro-F1 is the primary ranking metric to respect class balance across the five cancers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "615d8389",
   "metadata": {},
   "outputs": [],
   "source": [
    "cls_results, cls_models, idx_to_class = train_compare_classifiers(Xc, yc, RANDOM_STATE)\n",
    "\n",
    "log(\"Task 1 model sweep complete.\")\n",
    "cls_results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4025956d",
   "metadata": {},
   "source": [
    "## 5. Task 1 — Confusion Matrix & Per-Class Report\n",
    "The confusion matrix and class-wise precision/recall/F1 are required in the homework write-up. They are exported to `hw3_outputs/` and displayed here for quick inspection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25841b10",
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion = pd.read_csv(OUT_DIR / \"task1_confusion_matrix.csv\", index_col=0)\n",
    "classification_report_df = pd.read_csv(OUT_DIR / \"task1_classification_report.csv\", index_col=0)\n",
    "\n",
    "log(\"Task 1 evaluation artefacts loaded from hw3_outputs/.\")\n",
    "display(confusion)\n",
    "classification_report_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "167707c7",
   "metadata": {},
   "source": [
    "## 6. Task 2 — SHAP on Best Classifier\n",
    "The top-ranked classifier becomes the subject of SHAP analysis. We compute per-cancer top-10 genes and generate patient-level force plots for `TCGA-39-5011-01A` as mandated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9596004f",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_classifier_name = cls_results.iloc[0][\"Model\"]\n",
    "best_classifier = cls_models[best_classifier_name]\n",
    "\n",
    "log(f\"Task 2 interprets the {best_classifier_name}.\")\n",
    "shap_task2(best_classifier, Xc, yc, sample_ids, PATIENT_ID_TO_PLOT, idx_to_class)\n",
    "\n",
    "task2_top = pd.read_csv(OUT_DIR / \"task2a_top10_features_per_cancer.csv\")\n",
    "log(\"Task 2 SHAP tables saved to hw3_outputs/.\")\n",
    "task2_top.head(15)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e622313d",
   "metadata": {},
   "source": [
    "The five force plots above are also saved as HTML files in `hw3_outputs/task2b_forceplot_<Cancer>_patient_TCGA-39-5011-01A.html` for sharing or screenshot capture."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26e195d6",
   "metadata": {},
   "source": [
    "## 7. Task 3 — Regression Dataset Reconnaissance\n",
    "We repeat the data audit for the GDSC2 drug-response table, capturing dimensionality and ID columns to justify preprocessing choices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "208894f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "regression_path = resolve_data_path(REG_PRIMARY, REG_FALLBACK)\n",
    "assert regression_path is not None, \"Regression CSV missing – please place hw3-drug-screening-data.csv (renamed to GDSC2_13drugs.csv) alongside the notebook.\"\n",
    "\n",
    "Xr, yr, keys, meta = memory_savvy_read_gdsc2(regression_path, MAX_FEATURES_REGRESS)\n",
    "\n",
    "summary_reg = pd.DataFrame(\n",
    "    {\n",
    "        \"rows\": [meta[\"n_rows\"]],\n",
    "        \"selected_features\": [meta[\"n_features\"]],\n",
    "        \"target_column\": [meta[\"target\"]],\n",
    "        \"id_columns\": [\" & \".join(meta[\"id_cols\"])],\n",
    "    }\n",
    ")\n",
    "\n",
    "log(\"Task 3 dataset loaded.\")\n",
    "display(summary_reg)\n",
    "Xr.iloc[:5, :10]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b95ba23c",
   "metadata": {},
   "source": [
    "## 8. Task 3 — Regressor Comparison\n",
    "With preprocessing aligned to the classification case, we evaluate the regression ensemble and rank models using RMSE (primary) plus MAE/MSE/R²."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98259c6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_results, reg_models = train_compare_regressors(Xr, yr, RANDOM_STATE)\n",
    "\n",
    "log(\"Task 3 model sweep complete.\")\n",
    "reg_results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db5ddc06",
   "metadata": {},
   "source": [
    "## 9. Task 4 — SHAP on Best Regressor\n",
    "We apply SHAP to the top regressor to fulfil Tasks 4a and 4b: per-drug feature rankings and the least-error drug–cell-line explanation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3d0949f",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_regressor_name = reg_results.iloc[0][\"Model\"]\n",
    "best_regressor = reg_models[best_regressor_name]\n",
    "\n",
    "log(f\"Task 4 interprets the {best_regressor_name}.\")\n",
    "shap_task4(best_regressor, Xr, yr, keys)\n",
    "\n",
    "per_drug = pd.read_csv(OUT_DIR / \"task4a_top10_features_per_drug.csv\")\n",
    "least_error_path = sorted(OUT_DIR.glob(\"task4b_top10_features_least_error_*.csv\"))[-1]\n",
    "least_error = pd.read_csv(least_error_path)\n",
    "\n",
    "(per_drug.head(20), least_error)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aa1935a",
   "metadata": {},
   "source": [
    "## 10. Conclusion & Artefact Checklist\n",
    "- All tables/figures required by the assignment are in `hw3_outputs/`.\n",
    "- Rerun with different feature caps or SHAP sample sizes by adjusting the configuration cell at the top.\n",
    "- A natural extension is hyper-parameter tuning around the winning models or annotating the highlighted genes/drugs with biological context."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
